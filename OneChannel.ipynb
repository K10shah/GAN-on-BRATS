{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from medpy.io import load\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "PATH = os.path.join(os.path.dirname(os.path.abspath('__file__')), \"/home/ketan/Desktop/DCGAN_BRATS/BRATS2013/BRATS_Training/Image_Data/\")\n",
    "\n",
    "def pad_image(img, desired_shape=(256, 256)):\n",
    "    pad_top = 0\n",
    "    pad_bot = 0\n",
    "    pad_left = 0\n",
    "    pad_right = 0\n",
    "    if desired_shape[0] > img.shape[0]:\n",
    "        pad_top = int((desired_shape[0] - img.shape[0]) / 2)\n",
    "        pad_bot = desired_shape[0] - img.shape[0] - pad_top\n",
    "    if desired_shape[1] > img.shape[1]:\n",
    "        pad_left = int((desired_shape[1] - img.shape[1]) / 2)\n",
    "        pad_right = desired_shape[1] - img.shape[1] - pad_left\n",
    "    img = np.pad(img, ((pad_top, pad_bot), (pad_left, pad_right)), 'constant')\n",
    "    assert (img.shape == desired_shape)\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    nimg = None\n",
    "    nimg = cv.normalize(img, nimg, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)\n",
    "    nimg = pad_image(nimg, desired_shape=(256, 256))\n",
    "    return nimg\n",
    "\n",
    "\n",
    "def load_single_image(path):\n",
    "    for dir, subdir, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mha\"):\n",
    "                img = load_itk(os.path.join(path, file))\n",
    "                return img\n",
    "\n",
    "\n",
    "def create_1_chan_data(flair, ot):\n",
    "    ot_layers = []\n",
    "    flair_layers = []\n",
    "    for layer in range(ot.shape[2]):\n",
    "        ot_layers.append(pad_image(ot[:, :, layer], desired_shape=(256, 256)))\n",
    "        flair_layers.append(normalize(flair[:, :, layer]))\n",
    "\n",
    "    return np.stack(ot_layers, axis=0), np.stack(flair_layers, axis=0)\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    \n",
    "    train_flair = []\n",
    "    train_ot = []\n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        if dir == 'HG':\n",
    "            HG_path = os.path.join(path, 'HG')\n",
    "            for dir2 in os.listdir(HG_path):\n",
    "                if dir2 != '.DS_Store':\n",
    "                    HG_flair = load_single_image(os.path.join(HG_path, dir2, 'VSD.Brain.XX.O.MR_Flair'))\n",
    "                    HG_ot = load_single_image(os.path.join(HG_path, dir2, 'VSD.Brain_3more.XX.XX.OT'))\n",
    "                    assert (HG_ot.shape == HG_flair.shape )\n",
    "                    HG_samples = create_1_chan_data(HG_flair, HG_ot)\n",
    "                    train_ot.append(HG_samples[0])\n",
    "                    train_flair.append(HG_samples[1])\n",
    "\n",
    "        if dir == 'LG':\n",
    "            brain_1 = brain_2 = brain_3 = False\n",
    "            LG_path = os.path.join(path, 'LG')\n",
    "            for dir3 in os.listdir(LG_path):\n",
    "                if dir3 != '.DS_Store':\n",
    "                    LG_flair = load_single_image(os.path.join(LG_path, dir3, 'VSD.Brain.XX.O.MR_Flair'))\n",
    "                    brain_1 = os.path.exists(os.path.join(LG_path, dir3, 'VSD.Brain_1more.XX.XX.OT'))\n",
    "                    brain_2 = os.path.exists(os.path.join(LG_path, dir3, 'VSD.Brain_2more.XX.XX.OT'))\n",
    "                    brain_3 = os.path.exists(os.path.join(LG_path, dir3, 'VSD.Brain_3more.XX.XX.OT'))\n",
    "                    if brain_1:\n",
    "                        LG_ot = load_single_image(os.path.join(LG_path, dir3, 'VSD.Brain_1more.XX.XX.OT'))\n",
    "                    if brain_2:\n",
    "                        LG_ot = load_single_image(os.path.join(LG_path, dir3, 'VSD.Brain_2more.XX.XX.OT'))\n",
    "                    if brain_3:\n",
    "                        LG_ot = load_single_image(os.path.join(LG_path, dir3, 'VSD.Brain_3more.XX.XX.OT'))\n",
    "\n",
    "                    assert (LG_ot.shape == LG_flair.shape)\n",
    "                    LG_samples = create_1_chan_data(LG_flair, LG_ot)\n",
    "                    train_ot.append(LG_samples[0])\n",
    "                    train_flair.append(LG_samples[1])\n",
    "    # Stacking all individual layers\n",
    "    train_ot = np.vstack(train_ot)\n",
    "    train_flair = np.vstack(train_flair)\n",
    "    assert (train_ot.shape == train_flair.shape)\n",
    "    return np.array([train_flair,train_ot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from medpy.io import load\n",
    "'''\n",
    "This funciton reads a '.mhd' file using SimpleITK and return the image array, origin and spacing of the image.\n",
    "'''\n",
    "\n",
    "def load_itk(filename):\n",
    "    # Reads the image using SimpleITK\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "\n",
    "    # Convert the image to a  numpy array first and then shuffle the dimensions to get axis in the order z,y,x\n",
    "    ct_scan = sitk.GetArrayFromImage(itkimage)\n",
    "\n",
    "    # Read the origin of the ct_scan, will be used to convert the coordinates from world to voxel and vice versa.\n",
    "    origin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "\n",
    "    # Read the spacing along each dimension\n",
    "    spacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "\n",
    "#     return ct_scan, origin, spacing\n",
    "    return ct_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =load_dataset(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5417, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# fig1 = plt.figure()\n",
    "plt.imshow(x[0,100,:,:])\n",
    "plt.savefig('sample.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x[1,100,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imginput = x[0]\n",
    "imgoutput = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5417, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(imginput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5417, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(imgoutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.amax(imgoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(x[0,89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Image configuration\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "data_files = PATH\n",
    "shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT,1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(batch_size):\n",
    "    \"\"\"\n",
    "    Generate batches\n",
    "    \"\"\"\n",
    "    IMAGE_MAX_VALUE = 255\n",
    "\n",
    "\n",
    "    current_index = 0\n",
    "    while current_index + batch_size <= shape[0]:\n",
    "\n",
    "        data_batch = (x[0,current_index:current_index + batch_size])\n",
    "        print(type(data_batch))\n",
    "        print(data_batch.shape)\n",
    "        data_batch = data_batch[...,np.newaxis]\n",
    "        print(data_batch.shape)\n",
    "        \n",
    "\n",
    "#         np.vstack((data_batch, x[1,current_index:current_index + batch_size]))\n",
    "        \n",
    "        \n",
    "\n",
    "        current_index += batch_size\n",
    "        \n",
    "#         return data_batch / IMAGE_MAX_VALUE - 0.5\n",
    "        \n",
    "#         yield data_batch / IMAGE_MAX_VALUE - 0.5\n",
    "        print(\"db:\",data_batch.shape)\n",
    "        yield data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object get_batches at 0x7fbeb23fd308>\n"
     ]
    }
   ],
   "source": [
    "print(get_batches(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ketan/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    \"\"\"\n",
    "    inputs_real = tf.placeholder(tf.float32, shape=(None, image_width, image_height, image_channels), name='input_real') \n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    return inputs_real, inputs_z, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    print(\"image size:\",images.shape)\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # using 4 layer network as in DCGAN Paper\n",
    "        \n",
    "        # Conv 1\n",
    "        conv1 = tf.layers.conv2d(images, 64, 5, 2, 'SAME')\n",
    "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
    "        print(\"layer1:\",lrelu1.shape)\n",
    "        \n",
    "        # Conv 2\n",
    "        conv2 = tf.layers.conv2d(lrelu1, 128, 5, 2, 'SAME')\n",
    "        batch_norm2 = tf.layers.batch_normalization(conv2, training=True)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "        print(\"layer2:\",lrelu2.shape)\n",
    "\n",
    "        # Conv 3\n",
    "        conv3 = tf.layers.conv2d(lrelu2, 256, 5, 1, 'SAME')\n",
    "        batch_norm3 = tf.layers.batch_normalization(conv3, training=True)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "        print(\"layer3:\",lrelu3.shape)\n",
    "\n",
    "        # Flatten\n",
    "        flat = tf.reshape(lrelu3, (-1, 4*4*256))\n",
    "        print(\"layer4:\",flat.shape)\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        \n",
    "        # Output\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    \"\"\"\n",
    "    alpha = 0.2\n",
    "    print(\"gen,z:\",z.shape)\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=False if is_train==True else True):\n",
    "        # First fully connected layer\n",
    "        x_1 = tf.layers.dense(z, 32*32*512)\n",
    "        print(\"Gen,fully conn layer 1:\",x_1.shape)\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        deconv_2 = tf.reshape(x_1, (-1, 32, 32, 512))\n",
    "        batch_norm2 = tf.layers.batch_normalization(deconv_2, training=is_train)\n",
    "        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n",
    "        print(\"Gen,fully conn layer 1 reshape:\",lrelu2.shape)\n",
    "\n",
    "        \n",
    "        # Deconv 1\n",
    "        deconv3 = tf.layers.conv2d_transpose(lrelu2, 512, 5, 2, padding='SAME')\n",
    "        batch_norm3 = tf.layers.batch_normalization(deconv3, training=is_train)\n",
    "        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n",
    "        print(\"Gen,deconv layer 1 :\",lrelu3.shape)\n",
    "\n",
    "        \n",
    "        # Deconv 2\n",
    "        deconv4 = tf.layers.conv2d_transpose(lrelu3, 256, 5, 2, padding='SAME')\n",
    "        batch_norm4 = tf.layers.batch_normalization(deconv4, training=is_train)\n",
    "        lrelu4 = tf.maximum(alpha * batch_norm4, batch_norm4)\n",
    "        print(\"Gen,deconv layer 2 :\",lrelu4.shape)\n",
    "\n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(lrelu4, out_channel_dim, 5, 2, padding='SAME')\n",
    "        print(\"Gen,output layer :\",logits.shape)\n",
    "\n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    \"\"\"\n",
    "    \n",
    "    label_smoothing = 0.9\n",
    "    \n",
    "    g_model = generator(input_z, out_channel_dim)\n",
    "    d_model_real, d_logits_real = discriminator(input_real)\n",
    "    print(\"gmodel size\", g_model.shape)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n",
    "    \n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                labels=tf.ones_like(d_model_real) * label_smoothing))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.zeros_like(d_model_fake)))\n",
    "    \n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "                                                  \n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                labels=tf.ones_like(d_model_fake) * label_smoothing))\n",
    "    \n",
    "    \n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    \"\"\"\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, input_z, out_channel_dim):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    \"\"\"\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    pyplot.imshow(helper.images_square_grid(samples))\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape):\n",
    "    \"\"\"\n",
    "    Train the GAN\n",
    "    \"\"\"\n",
    "    input_real, input_z, _ = model_inputs(data_shape[1], data_shape[2], data_shape[3], z_dim)\n",
    "    d_loss, g_loss = model_loss(input_real, input_z, data_shape[3])\n",
    "    d_opt, g_opt = model_opt(d_loss, g_loss, learning_rate, beta1)\n",
    "    \n",
    "    steps = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch_i in range(epoch_count):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                \n",
    "                # values range from -0.5 to 0.5, therefore scale to range -1, 1\n",
    "                batch_images = batch_images * 2\n",
    "                steps += 1\n",
    "            \n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "                print(\"Batch:\",batch_images.shape)\n",
    "                print(\"Batch Z:\",batch_z.shape)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                _ = sess.run(d_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                _ = sess.run(g_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                \n",
    "                if steps % 400 == 0:\n",
    "                    # At the end of every 10 epochs, get the losses and print them out\n",
    "                    train_loss_d = d_loss.eval({input_z: batch_z, input_real: batch_images})\n",
    "                    train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(epoch_i+1, epochs),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    \n",
    "                    _ = show_generator_output(sess, 1, input_z, data_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen,z: (?, 1)\n",
      "Gen,fully conn layer 1: (?, 524288)\n",
      "Gen,fully conn layer 1 reshape: (?, 32, 32, 512)\n",
      "Gen,deconv layer 1 : (?, 64, 64, 512)\n",
      "Gen,deconv layer 2 : (?, 128, 128, 256)\n",
      "Gen,output layer : (?, 256, 256, 1)\n",
      "image size: (?, 256, 256, 1)\n",
      "layer1: (?, 128, 128, 64)\n",
      "layer2: (?, 64, 64, 128)\n",
      "layer3: (?, 64, 64, 256)\n",
      "layer4: (?, 4096)\n",
      "gmodel size (?, 256, 256, 1)\n",
      "image size: (?, 256, 256, 1)\n",
      "layer1: (?, 128, 128, 64)\n",
      "layer2: (?, 64, 64, 128)\n",
      "layer3: (?, 64, 64, 256)\n",
      "layer4: (?, 4096)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(5, 256, 256)\n",
      "(5, 256, 256, 1)\n",
      "db: (5, 256, 256, 1)\n",
      "Batch: (5, 256, 256, 1)\n",
      "Batch Z: (5, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-802748a09734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-babe096d3cd4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "z_dim = 1\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "epochs = 2\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    train(epochs, batch_size, z_dim, learning_rate, beta1, get_batches, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
